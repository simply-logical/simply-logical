## 8: Reasoning with incomplete information ##

In everyday life, we use a surprising number of different reasoning methods, exemplified by the following arguments:

- &lsquo;It is getting dark already, it must be after five.&rsquo;
- &lsquo;If I push this button, the light in my room will switch on.&rsquo;
- &lsquo;The light doesn&rsquo;t switch on!? The lightbulb must be broken!&rsquo;

The first argument is based on general knowledge about the regular hours of sunset. This knowledge is reached after numerous observations, and it is embedded in a theory about the movements of the heavenly bodies. We are pretty confident that this theory is **true**; that is, it accurately describes the actual state of affairs. This justifies its use to predict events in the future. However, it should be noted that we can never be **absolutely** sure that the theory is true: tomorrow the sun may set at eleven in the morning, falsifying our theory. The theory is reached by *induction*: given a number of distinct but similar observations, conclude that they are governed by a general law. Induction is an important reasoning method in the natural sciences, and it also underlies some forms of learning, like *learning from examples*. Despite this common usage, it is surprisingly hard to formalise inductive reasoning: in particular, what it takes to *justify* an inductive hypothesis remains a largely unresolved question.

The second argument above seems perfectly alright, given knowledge about how the switch is connected to the lightbulb and the power supply. However, this argument requires a lot of implicit assumptions: the switch is not broken, the connections are in order, the lightbulb is not broken, there is a supply of power, and so on. The argument is not in general true, but it describes the normal case; there might be some exceptional circumstance, invalidating the argument. Typically, we assume things to be normal, unless there is evidence to the contrary. We call this *default reasoning*.

In the third argument, we give an *explanation* for the observation that the light doesn&rsquo;t switch on. It is a sort of reversed implication: we know that if the lightbulb is broken, the light won&rsquo;t switch on; we observe that the light doesn&rsquo;t work, so we conclude that the lightbulb must be broken. This is but one of several possible explanations, however: the switch might be broken, or the power supply might be down. This process of finding explanations for observed facts is called *abduction*.

The common characteristic of these three types of reasoning is that their conclusions, however plausible they may seem, are not guaranteed to be true in the intended interpretation, because the information we have is *incomplete*. In default reasoning, the conclusion might be false because the state of affairs is not so normal as it is assumed to be. In abduction, there might be several alternative explanations, and we do not know which one to choose. In induction, we typically base our conclusion on only a fraction of the possible observations. Thus, the general rule (e.g. all swans are white) might be invalidated by the next observation (a black swan).

In other words, such common-sense arguments are *unsound*. Recall that an inference rule is sound if the truth of its conclusion is guaranteed by the truth of its premises. Sound reasoning is also called *deduction*; it is the only allowed form of reasoning in fields where rigorous arguments are needed, like mathematics. However, deductive conclusions only make explicit what is already implicitly present in the premises (e.g. the mathematical axioms, or a logic program). In everyday reasoning we often want to reach conclusions which contain **new** information, information that is not present in the premises. In this chapter, we will take a closer look at various forms of reasoning with incomplete information, such as default reasoning, abduction, and diagnostic reasoning. Inductive reasoning is a subject which deserves a chapter of its own (Chapter 9).
